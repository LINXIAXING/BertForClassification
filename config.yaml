# The name of model
describe: "bert"
trainer:
  seed: 42
  checkpoint: './checkpoint'
  epochs: 100
  # evaluate every eval_step epochs
  eval_step: 1
  # when the last save_all_epoch was false, the restore_train of this time will not work
  restore_train: False
  save_all_epoch: True
  # accelerator
  mixed_precision: 'no'
  gradient_accumulation_steps: 1
  model:
    # local path of model or hugging face pretrain_model name
    pretrain_model: "./pretrain_checkpoint/bert" # "IDEA-CCNL/Taiyi-CLIP-RoBERTa-326M-ViT-H-Chinese" and "bert-base-chinese"
    num_labels: 3
    classifier_dropout: 0.1
  dataset:
    paths:
#      - './dataset/beng.csv'
#      - './dataset/ji.csv'
#      - './dataset/xiao.csv'
      - './dataset/neg.csv'
      - './dataset/neutral.csv'
      - './dataset/pos.csv'
    labels:
#      - 'beng'
#      - 'ji'
#      - 'xiao'
      - 'negative'
      - 'neutral'
      - 'positive'
    train_ratio: 0.8
    batch_size: 18
  optim:
    lr: 0.00002
    weight_decay: 0.05
  scheduler:
    T_0: 1
    T_mult: 2

onnx:
  # onnx generator will load the newest checkpoint by describe when other.describe is None
  describe: ""
  save_path: "./onnx"